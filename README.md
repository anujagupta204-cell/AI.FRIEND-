# Voice AI Friend ü§ç

A production-ready Voice AI Friend that provides real-time, empathetic voice conversations with ultra-low latency.

## ‚ú® Features

- **Real-time Voice Conversation**: Talk naturally using your microphone
- **Ultra-Low Latency**: <100ms for cached responses, <500ms for novel inputs
- **Male/Female Voice Options**: Choose your preferred voice from the UI
- **Emotionally Intelligent**: Trained on 30K+ empathetic conversation examples
- **Premium UI**: Modern glassmorphism design with smooth animations
- **Browser-Native**: Uses Web Speech API for instant ASR and TTS
- **Smart Caching**: O(1) response lookup for common emotional inputs
- **Fallback LLM**: GPT-3.5-turbo for handling novel conversations

## üöÄ Quick Start

### Prerequisites

- Node.js 16+ installed
- Modern browser (Chrome or Edge recommended for best Web Speech API support)
- OpenAI API key (optional, for advanced responses)

### Installation

1. **Install dependencies**:
```bash
npm install
```

2. **Configure environment** (optional):
```bash
# Copy the example env file
cp .env.example .env

# Edit .env and add your OpenAI API key (optional)
# If you don't add an API key, the system will use cache-only mode
```

3. **Start the server**:
```bash
npm start
```

4. **Open in browser**:
```
http://localhost:3000
```

## üé§ How to Use

1. **Select Voice**: Click the Female üë© or Male üë® button to choose your preferred voice
2. **Start Talking**: Click the microphone button and speak
3. **Or Type**: Type your message in the text input and press Enter
4. **Listen**: The AI will respond with voice and text

## üèóÔ∏è Architecture

```
Frontend (Browser)
‚îú‚îÄ‚îÄ Web Speech API (ASR) - Speech-to-text
‚îú‚îÄ‚îÄ WebSocket Client - Real-time communication
‚îú‚îÄ‚îÄ Web Speech Synthesis (TTS) - Text-to-speech
‚îî‚îÄ‚îÄ Audio Visualizer - Visual feedback

Backend (Node.js)
‚îú‚îÄ‚îÄ Express Server - HTTP server
‚îú‚îÄ‚îÄ WebSocket Server - Real-time communication
‚îú‚îÄ‚îÄ Dataset Loader - O(1) keyword-indexed cache
‚îú‚îÄ‚îÄ AI Pipeline - Cache-first + LLM fallback
‚îî‚îÄ‚îÄ Configuration - Centralized settings
```

## üìä Performance

The system is optimized for ultra-low latency:

- **Cache Hit**: ~1-5ms (keyword lookup)
- **LLM Fallback**: ~50-200ms (GPT-3.5-turbo)
- **TTS**: ~0ms (browser-native, instant)
- **Total**: <100ms for cached, <500ms for novel inputs

Run the latency test:
```bash
npm test
```

## üóÇÔ∏è Project Structure

```
c:/AI FREIND/
‚îú‚îÄ‚îÄ index.html              # Frontend UI
‚îú‚îÄ‚îÄ style.css               # Premium styling
‚îú‚îÄ‚îÄ app.js                  # Frontend logic
‚îú‚îÄ‚îÄ server.js               # Main backend server
‚îú‚îÄ‚îÄ dataset-loader.js       # Dataset indexing
‚îú‚îÄ‚îÄ ai-pipeline.js          # AI response logic
‚îú‚îÄ‚îÄ config.js               # Configuration
‚îú‚îÄ‚îÄ package.json            # Dependencies
‚îú‚îÄ‚îÄ .env.example            # Environment template
‚îú‚îÄ‚îÄ README.md               # This file
‚îú‚îÄ‚îÄ test-latency.js         # Performance testing
‚îî‚îÄ‚îÄ ai_friend_dataset.txt   # Training data (30K+ conversations)
```

## üé® Customization

### Change Voice Settings

Edit `config.js`:
```javascript
voice: {
  default: 'female', // or 'male'
  enablePremium: false,
}
```

### Adjust Performance Settings

Edit `config.js`:
```javascript
performance: {
  cacheEnabled: true,
  maxCacheSize: 10000,
  responseTimeout: 5000,
}
```

### Modify AI Personality

The AI personality is defined by the dataset (`ai_friend_dataset.txt`). To customize:
1. Edit the dataset with your own conversation examples
2. Restart the server to reload

## üåê Deployment

Since this project has a Node.js backend, it cannot run entirely on GitHub Pages. You must host the backend on **Render.com** (which is free) and the frontend on **GitHub Pages**.

### 1. Deploy the Backend (Render)
1. Create a free account on [Render.com](https://render.com).
2. Click **New +** and select **Web Service**.
3. Connect your GitHub repository.
4. Render will automatically detect the settings from `render.yaml`.
5. Go to the **Environment** tab in Render and add your `OPENAI_API_KEY`.
6. Once deployed, copy your Render URL (e.g., `https://voice-ai-friend.onrender.com`).

### 2. Update the Frontend
1. Open `app.js` in your code editor.
2. Find the line: `const productionWsUrl = 'wss://your-backend-name.onrender.com';` (around line 204).
3. Replace the placeholder URL with your actual Render URL (change `https://` to `wss://`).
4. Commit and push your changes to GitHub.

### 3. Deploy to GitHub Pages
1. Go to your GitHub repository **Settings > Pages**.
2. Select the `main` branch (or your current branch) as the source and click **Save**.
3. Your site will be live at `https://yourusername.github.io/your-repo-name/`.

### Deploy to Heroku

1. Create Heroku app:
```bash
heroku create voice-ai-friend
```

2. Set environment variables:
```bash
heroku config:set OPENAI_API_KEY=your_key_here
```

3. Deploy:
```bash
git push heroku main
```

## üîß Troubleshooting

### "Speech recognition not supported"
- Use Chrome or Edge browser (best Web Speech API support)
- Ensure you're using HTTPS (required for mic access)

### "WebSocket connection failed"
- Check that the server is running (`npm start`)
- Verify firewall settings allow WebSocket connections
- Check browser console for detailed error messages

### "No voice output"
- Check browser audio settings
- Ensure volume is not muted
- Try refreshing the page to reload voices

### High latency
- Check your internet connection (for LLM calls)
- Verify OpenAI API key is valid
- Run `npm test` to measure performance
- Check server logs for bottlenecks

## üìù API Reference

### WebSocket Messages

**Client ‚Üí Server:**
```javascript
// User message
{
  type: 'user_message',
  text: 'I feel lonely'
}

// Voice config
{
  type: 'voice_config',
  gender: 'female' // or 'male'
}

// Keep-alive
{
  type: 'ping'
}
```

**Server ‚Üí Client:**
```javascript
// AI response
{
  type: 'ai_response',
  text: 'I\'m here for you',
  source: 'cache', // or 'llm' or 'fallback'
  latency: 5,
  voiceGender: 'female'
}

// Error
{
  type: 'error',
  message: 'Error description'
}
```

## ü§ù Contributing

This is a production-ready starter project. Feel free to:
- Add more conversation examples to the dataset
- Improve the UI/UX
- Optimize performance further
- Add new features (emotion detection, conversation history, etc.)

## üìÑ License

MIT License - feel free to use this project for personal or commercial purposes.

## üôè Acknowledgments

- Built with Web Speech API for ultra-low latency
- Powered by OpenAI GPT-3.5-turbo (optional)
- Designed with modern web standards
- Optimized for real-time performance

---

**Made with ü§ç for empathetic AI conversations**
